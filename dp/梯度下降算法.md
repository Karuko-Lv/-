Gradient descent
🧚‍♀️梯度下降就是一个最优化方法吧？ ；是的，梯度下降就是一个**最优化方法**。**反向传播** 负责告诉你“往哪走”（计算出梯度）。**梯度下降** 负责“真正走起来”（利用梯度去更新参数）。一个负责指路，一个负责干活。
Mnist 数字图像的分辨率为 $28 \times 28$ 像素每个像素
随意选取2 层隐藏层每层 16 个神经元，整个网络有 13000 多个权重偏置值可以调整，这些数值决定网络实际做的工作

想要一种算法，给网络看一堆训练数据，希望分层结构可以让模型学会识别训练数据之外的图像