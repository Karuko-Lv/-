 Back propagation
计算梯度的算法 BP

❓神经网络怎么样前馈信息的？==>**加权、激活、传递**
学习就是找到特定的权重偏置使得一个代价函数最小化 

Loss 函数告诉如何改变所有连线上的权重偏置，好让代价下降最快
梯度向量每一项的大小是代价函数对每个参数敏感程度的刻画
🧚‍♀️严格来说，改变量应为无穷小（至少足够小）；注意，只是在这个点处的梯度；不同的神经元不是有不同的权重数组吗，图形上一组梯度不是应该对应同个神经元的不同权重吗


代价函数涉及到成千上万个训练样本的代价取平均值，原则上调整每一步梯度下降用的权重偏置也会基于所有的训练样本
为了计算效率（不希望每一步都得计算所有训练样本）
❓❓❓❓❓单个训练数据会具体让每个权重和每个偏置产生怎样的变化 
如果网络没有被完全训练好，输出层的激活值就会看起来很随机，首先不能直接改动激活值，只能改变权重和偏置值，但是得记住最终的目标（输出层的变动），变动的大小应该和现在值与目标值之间的差呈正比
![[截屏2026-01-20 16.29.47.png]] 🧚‍♀️小批量；只改权重的化还会有相同的；可以不训练，直接反向传播得到权重吗；那样会导致欠拟合；挤压函数翻译的很好啊，3 b 1 b 在第一个视频初次提到激活函数的概念时，就是用“挤压”数轴来表示的、
想增加激活值，有三种方法：1️⃣增加偏置 2️⃣增加权重 3️⃣改变上一层的激活值![[截屏2026-01-20 16.40.00.png]]
如何调整权重？
各个权重的影响力各不相同，连接前一层最亮的神经元的权重影响力也最大，这些权重会和大的激活值相乘==>梯度下降不只是看每个参数应该增大还是减小，还应该看哪个参数性价比最高，这里权重的最大增长即连接变得更强的部分就会发生在已经最活跃的神经元和想要更多激发的神经元之间
🧚‍♀️不是权重大，是影响力大，激活值越大，一个权重与他相乘，得到的值越大；这里其实是，上一层的 a_j 越大，w_j ... 的影响就越大；赫布理论就是说，一同激活的神经元在反复激活的时候，会不断强化连接的部分；可是如果前面几层权重和激活值变了岂不是这层激活值最高的节点就不一样了，是不是应该从左到右啊？（小白没想明白轻喷；我咋觉得这就是一个线性回归的分步版呢；加强神经元之间“看到”与“想到”的联系，这是赫布学习法则；因為要趨近於 1，所以正加權項產出越高，負數加權項產出越低，這樣越好；红线表示负梯度的值为负数，所以权重值要沿负梯度方向变化，即红色线的梯度值变小；同理即可推出蓝线权重变化。；反向传播 = 反向（后层对前层） + 传播（前后层层相邻）；纠正一下弹幕：反向传播不是黑箱，是因为原理懂但是计算复杂，采用计算机计算的；2 以外的箭头标反了；❌是有可能权值震荡最终无法收敛，这种时候就比较头疼，可能需要重新设计网络，用一些 trick 之类的；反向升维成上一层维度的矩阵，就可以用上一层输出值经过矩阵算出输入值的改变量，最后再以此改变上一层的权重![[截屏2026-01-20 17.01.05.png]]
每个输出神经元对于如何改变导数第二次都有各自的想法，加起来作为如何改变导数第二层神经元的指示，这种期待变化不仅是对应的权重的倍数，也就是每个神经元激活值改变量的倍数-->反向传播

重复以上步骤改变影响导数第二层神经元激活值的相关参数，从后一层到前一层直到循环到第一层
最后再对其他所有的训练样本同样过一遍反向传播
![[截屏2026-01-20 17.15.26.png]] ![[截屏2026-01-20 17.15.47.png]]
🧚‍♀️每个手写字符对应一个单独的神经网络吗，要不然是不是互相影响；我只知道 pandas 跑这个，内存起码得 20 g；通常不取平均值，而使用 SGD，否则无法收敛；因为你最后分类是分辨不同的数字，而非只有 2 呀。要在 2 号神经元高的时候其它低，其它高的时候 2 要低；这里是对期望的 change 做平均；如果只是相同数字求平均, 只会增大判别为这个数字的概率吧 

**这一系列的权重偏置的平均微调大小不严格来说就是上期视频提到的代价函数的负梯度**或者至少是其标量的倍数
不严格指的是没有准确解释如何量化这些微调
🧚‍♀️这是对所有的求平均值，因为这个系统对 0 到 9 用的都是一样的 w 和 b 和 a；应该是求了平均才能适用于那 10 个数；这里是对不同对象图片取整体识别最优的参数；因为是一个 batch 里面？所以用一批参数？；需要设个期待值权重来算加权平均吗

实际操作中如果梯度下降的每一步都用上每一个训练样本去计算花的时间就会非常长
